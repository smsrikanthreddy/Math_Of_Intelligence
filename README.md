 # Math_Of_Intelligence
This is a siraj raval course for Machine learning

The course link and syllabus page is below
https://github.com/llSourcell/The_Math_of_Intelligence

Each week has a short video (released on Friday) and an associated longer video (released on Wednesday). So each weeks short video is in bold and the longer video is underneath.<br>
Week 1 - First order optimization - derivative, partial derivative, convexity<br>
  SVM Classification with gradient descent<br>
Week 2 - Second order optimization - Jacobian, hessian, laplacian<br>
  Newtons method for logistic regression<br>
Week 3 - Vectors - Vector spaces, vector norms, matrices<br>
  K Means Clustering Algorithm<br>
Week 4 - Matrix operations - Dot product, matrix inverse, projections<br>
  Convolutional Neural Network<br>
Week 5 - Dimensionality Reduction - matrix decomposition, eigenvectors, eigenvalues<br>
  Recurrent Neural Network<br>
Week 6 - Probability terms - Random variables,Expectations,Variance<br>
  Random Forests<br>
Week 7 - Parameter estimation - expectation maximization, bayes vs frequentist, maximum likelihood estimation<br>
  XGBoost<br>
Week 8 - Types of Probability - joint, conditional, bayes rule, chain rule<br>
  The Fundamental Theorem of Linear Algebra<br>
Week 9 - T-SNE<br>
  Naive Bayes Classification<br>
Week 10 - Sampling -MCMC, Gibbs, Slice<br>
  LDA<br>
Week 11 - Popular Distributions - Bernoulli, uniform, multinomial<br>
  Gaussian Mixture Models<br>
Week 12 - Reinforcement - Markov chains, Monte Carlo, Markov Decision Processes<br>
  Game Bot<br>
